# Some resources for Machine Learning

Very personal and biased recommendation of ML resources.

## Table of Contents
- [Machine Learning](#machine-learning)
- [Deep Learning](#deep-learning)
- [Reinforcement Learning](#reinforcement-learning)
- [Graphical Model](#graphical-model)
- [Learning Theory](#learning-theory)
- [Online Learning](#online-learning)


## Machine Learning
There are many ML books, but most of them are encyclopedic. <br/>
I recommend to take a course using Murphy or Bishop book.

### Textbook
- Machine Learning: A Probabilistic Perspective (Murphy) :sparkles:
- Pattern Recognition and Machine Learning (Bishop) :sparkles:
- The Elements of Statistical Learning (Hastie et al.)
- Pattern Classification (Duda et al.)
- Bayesian Reasoning and Machine Learning (Barber)
- Information Theory, Inference, and Learning Algorithms (MacKay)

### Lecture
- [Stanford CS229 Machine Learning](http://cs229.stanford.edu)
- [CMU 10701 Mahine Learning](http://www.cs.cmu.edu/~tom/10701_sp11/)
- [Oxford Machine Learning](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)


## Deep Learning
Goodfellow et al. is new classic. <br/>
For CNN (vision) and RNN (NLP), Stanford lectures would be helpful.

### Textbook
- Deep Learning (Goodfellow et al.) :sparkles:

### Lecture
- [Stanford CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu)
- [Stanfrod CS224d Deep Learning for Natural Language Processing](http://cs224d.stanford.edu)
- [Oxford Deep Natural Language Processing](https://github.com/oxford-cs-deepnlp-2017/lectures)


## Reinforcement Learning
For classic (non-deep) RL, Sutton & Barto is classic. <br/>
For deep RL, lectures from Berkeley and CMU looks good.

### Textbook
- Reinforcement Learning: An Introduction (Sutton & Barto) :sparkles:
- Algorithms for Reinforcement Learning (Szepesv\'ari)
- Dynamic Programming and Optimal Control (Bertsekas)

### Lecture
- [UCL Reinforcement Learning](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
- [Berkeley CS294 Deep Reinforcement Leanring](http://rll.berkeley.edu/deeprlcourse/)
- [CMU 10703 Deep Reinforcement Learing and Control](https://katefvision.github.io/)


## Graphical Model
Koller & Friedman is comprehensive, but too encyclopedic. <br/>
I recommend to take an introductory course using Koller & Friedman book. <br/>

Wainwright & Jordan only focuses on variational inference, <br/>
but it is must-read book for probabilistic model, e.g. generative model.

### Textbook
- Probabilistic Graphical Models: Principles and Techniques (Koller & Friedman)
- Graphical Models, Exponential Families, and Variational Inference (Wainwright & Jordan) :sparkles:

### Lecture
- [Stanford CS228 Probabilistic Graphical Models](http://cs.stanford.edu/~ermon/cs228/index.html)
- [CMU 10708 Probabilistic Graphical Models](http://www.cs.cmu.edu/~epxing/Class/10708/)


## Learning Theory
Kearns & Vazirani is classic, but personally I think it is too outdated. <br/>
Abu-Mostafa and Shalev-Shwartz & Ben-David is enough to grasp the concept of learning theory.

### Textbook
- Learning from Data (Abu-Mostafa)
- Understanding Machine Learning: From Theory to Algorithms (Shalev-Shwartz & Ben-David)
- An Introduction to Computational Learning Theory (Kearns & Vazirani) 

### Lecture
- [Caltech Learning from Data](https://work.caltech.edu/telecourse.html)
- [CMU Machine Learning Theory](http://www.cs.cmu.edu/~avrim/ML14/)


## Online Learning
Cesa-Bianchi & Lugosi is the classic. <br/>
Frankly speaking, I didn't read it yet; so cannot talk in detail.

### Textbook
- Prediction, Learning, and Games (Cesa-Bianchi & Lugosi) :sparkles:
- Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems (Bubeck & Cesa-Bianchi)

### Lecture
- [UPenn Stat928 Statistical Learning Theory](http://stat.wharton.upenn.edu/~skakade/courses/stat928/)
