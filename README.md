# Some resources for Machine Learning

Very personal and biased recommendation of ML resources. <br/>
**Disclaimer**: I'm a noivce in ML research, and I read only a few of the list.

## Table of Contents
- [Machine Learning](#machine-learning)
- [Deep Learning](#deep-learning)
- [Reinforcement Learning](#reinforcement-learning)
- [Graphical Model](#graphical-model)
- [Optimization](#optimization)
- [Learning Theory](#learning-theory)
- [Online Learning](#online-learning)
- [Information Theory](#information-theory)
- [Network Science](#network-science)


## Machine Learning
There are many ML books, but most of them are encyclopedic. <br/>
I recommend to take a course using Murphy or Bishop book.

### Textbook
- Machine Learning: A Probabilistic Perspective (Murphy) :sparkles:
- Pattern Recognition and Machine Learning (Bishop) :sparkles:
- The Elements of Statistical Learning (Hastie et al.)
- Pattern Classification (Duda et al.)
- Bayesian Reasoning and Machine Learning (Barber)

### Lecture
- [Stanford CS229 Machine Learning](http://cs229.stanford.edu)
- [CMU 10701 Mahine Learning](http://www.cs.cmu.edu/~tom/10701_sp11/)
- [Oxford Machine Learning](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)


## Deep Learning
Goodfellow et al. is new classic. <br/>
For vision and NLP, Stanford lectures would be helpful.

### Textbook
- Deep Learning (Goodfellow et al.) :sparkles:

### Lecture
- [Stanford CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu)
- [Stanfrod CS224d Deep Learning for Natural Language Processing](http://cs224d.stanford.edu)
- [Oxford Deep Natural Language Processing](https://github.com/oxford-cs-deepnlp-2017/lectures)

### Tutorial
- [ICML 2017 Sequence-To-Sequence Modeling with Neural Networks](https://sites.google.com/view/seq2seq-icml17)


## Reinforcement Learning
For classic (non-deep) RL, Sutton & Barto is classic. <br/>
For deep RL, lectures and tutorials would be better.

### Textbook
- Reinforcement Learning: An Introduction (Sutton & Barto) :sparkles:
- Algorithms for Reinforcement Learning (Szepesvári)
- Dynamic Programming and Optimal Control (Bertsekas)

### Lecture
- [UCL Reinforcement Learning](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
- [Berkeley Deep RL Bootcamp](https://sites.google.com/view/deep-rl-bootcamp/lectures)
- [Berkeley CS294 Deep Reinforcement Leanring](http://rll.berkeley.edu/deeprlcourse/)
- [CMU 10703 Deep Reinforcement Learing and Control](https://katefvision.github.io/)

### Tutorial
- [ICML 2017 Deep Reinforcement Learning, Decision Making, and Control](https://sites.google.com/view/icml17deeprl)


## Graphical Model
Koller & Friedman is comprehensive, but too encyclopedic. <br/>
I recommend to take an introductory course using Koller & Friedman book. <br/>

Wainwright & Jordan only focuses on variational inference, <br/>
but it is must-read book for probabilistic model, e.g. generative model.

### Textbook
- Probabilistic Graphical Models: Principles and Techniques (Koller & Friedman)
- Graphical Models, Exponential Families, and Variational Inference (Wainwright & Jordan) :sparkles:

### Lecture
- [Stanford CS228 Probabilistic Graphical Models](http://cs.stanford.edu/~ermon/cs228/index.html)
- [CMU 10708 Probabilistic Graphical Models](http://www.cs.cmu.edu/~epxing/Class/10708/)


## Optimization
Boyd & Vandenberghe is classic, but personally I think it is boring. <br/>
Reading chapter 2-5 and understanding Fenchel's duality would be enough.

Rockafellar and Bertsekas more concentrates on convex analysis. <br/>
Nocedal & Wright more concentrates on optimization.

### Textbook
- Convex Optimization (Boyd & Vandenberghe) :sparkles:
- Convex Analysis (Rockafellar)
- Convex Optimization Theory (Bertsekas)
- Numerical Optimization (Nocedal & Wright)

### Lecture
- [Stanford EE364a Convex Optimization I](http://stanford.edu/class/ee364a/)
- [Stanford EE364b Convex Optimization II](http://stanford.edu/class/ee364a/)
- [MIT Convex Analysis and Optimization](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-253-convex-analysis-and-optimization-spring-2012/index.htm)

### Tutorial
- [ICML 2017 Recent Advances in Stochastic Convex and Non-Convex Optimization](http://people.csail.mit.edu/zeyuan/topics/icml-2017)


## Learning Theory
Kearns & Vazirani is classic, but personally I think it is old-fashioned. <br/>
Abu-Mostafa and Shalev-Shwartz & Ben-David is enough to grasp the concept.

### Textbook
- Learning from Data (Abu-Mostafa)
- Understanding Machine Learning: From Theory to Algorithms (Shalev-Shwartz & Ben-David)
- An Introduction to Computational Learning Theory (Kearns & Vazirani) 

### Lecture
- [Caltech Learning from Data](https://work.caltech.edu/telecourse.html)
- [CMU 15859 Machine Learning Theory](http://www.cs.cmu.edu/~avrim/ML14/)


## Online Learning
Cesa-Bianchi & Lugosi is classic. <br/>

### Textbook
- Prediction, Learning, and Games (Cesa-Bianchi & Lugosi)
- Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems (Bubeck & Cesa-Bianchi)

### Lecture
- [UPenn Stat928 Statistical Learning Theory](http://stat.wharton.upenn.edu/~skakade/courses/stat928/)


## Information Theory
Cover & Thomas is classic. <br/>

### Textbook
- Elements of Information Theory (Cover & Thomas) :sparkles:
- Information Theory, Inference, and Learning Algorithms (MacKay)

### Lecture
- [Stanford EE376a Information Theory](http://web.stanford.edu/class/ee376a/)
- [Cambridge Information Theory, Pattern Recognition, and Neural Networks](http://www.inference.org.uk/itprnn/)


## Network Science
Easley & Kleinberg is classic.

### Textbook
- Networks, Crowds, and Markets (Easley & Kleinberg)
- Network Science (Barabási)
- Random Graphs (Bollobás)

### Lecture
- [Stanford CS224w Analysis of Networks](http://web.stanford.edu/class/cs224w/)
